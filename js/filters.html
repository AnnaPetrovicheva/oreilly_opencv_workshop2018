<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>Face Detection Camera Example</title>
<link href="files/js_example_style.css" rel="stylesheet" type="text/css" />
</head>
<body>
<h2>Image Filtering Example</h2>
<p>
    Click <b>Start/Stop</b> button to start or stop the camera capture.<br>
    The <b>videoInput</b> is a &lt;video&gt; element used as filtered image output.
    The <b>canvasOutput</b> is a &lt;canvas&gt; element used as face detector output.<br>
    Use combobox to select applied filter<br>
</p>
<div>
<div class="control">
    <button id="startAndStop" disabled>Start</button></br>
    Filter type:
    <select name="effectSelector" id="effectSelector">
        <option value="Blur">Blur</option>
        <option value="Zoom">Zoom</option>
        <option value="Canny">Canny</option>
    </select>
</div>
<p class="err" id="errorMessage"></p>
<div>
    <table cellpadding="0" cellspacing="0" width="0" border="0">
    <tr>
        <td>
            <video id="videoInput" width=320 height=240></video>
        </td>
        <td>
            <canvas id="canvasOutput" width=320 height=240></canvas>
        </td>
    </tr>
    <tr>
        <td>
            <div class="caption">videoInput</div>
        </td>
        <td>
            <div class="caption">canvasOutput</div>
        </td>
    </tr>
    </table>
</div>
<script src="files/utils.js" type="text/javascript"></script>
<script type="text/javascript">
let utils = new Utils('errorMessage');

let streaming = false;
let videoInput = document.getElementById('videoInput');
let startAndStop = document.getElementById('startAndStop');
let canvasOutput = document.getElementById('canvasOutput');
let effectSelector = document.getElementById('effectSelector');
let canvasContext = canvasOutput.getContext('2d');

let BLUR_FILTER = 0
let ZOOM_FILTER = 1
let CANNY_FILTER = 2

function main() {
    let video = document.getElementById('videoInput');
    let cap = new cv.VideoCapture(video);
    let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
    let dst = new cv.Mat(video.height, video.width, cv.CV_8UC4);
    let kernelSize = new cv.Size(5,5);
    let roiRect = new cv.Rect(80,60,160,120);
    let roi = new cv.Mat(video.height/2, video.width/2, cv.CV_8UC4);
    let resizeFactor = new cv.Size(video.width, video.height);
    const FPS = 30;

    function processVideo() {
        if (!streaming) {
            src.delete();
            dst.delete();
            roi.delete();
            return;
        }

        let begin = Date.now();
        cap.read(src);
        switch(effectSelector.selectedIndex)
        {
            case BLUR_FILTER:
            {
                cv.blur(src, dst, kernelSize);
            } break;
            case ZOOM_FILTER:
            {
                roi = src.roi(roiRect);
                cv.resize(roi, dst, resizeFactor);
            } break;
            case CANNY_FILTER:
            {
                cv.Canny(src, dst, 80, 90);
            } break;
        }
        cv.imshow('canvasOutput', dst);
        let delay = 1000/FPS - (Date.now() - begin);
        setTimeout(processVideo, delay);
    };

    setTimeout(processVideo, 0);
}

startAndStop.addEventListener('click', () => {
    if (!streaming) {
        utils.clearError();
        utils.startCamera('qvga', onVideoStarted, 'videoInput');
    } else {
        utils.stopCamera();
        onVideoStopped();
    }
});

function onVideoStarted() {
    streaming = true;
    startAndStop.innerText = 'Stop';
    videoInput.width = videoInput.videoWidth;
    videoInput.height = videoInput.videoHeight;
    main();
}

function onVideoStopped() {
    streaming = false;
    canvasContext.clearRect(0, 0, canvasOutput.width, canvasOutput.height);
    startAndStop.innerText = 'Start';
}

utils.loadOpenCv(() => {
    startAndStop.removeAttribute('disabled');
});
</script>
</body>
</html>
